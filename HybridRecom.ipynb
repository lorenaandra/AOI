{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from collections import defaultdict\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "nr_of_recommendations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>subject_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arXiv:2310.03720</td>\n",
       "      <td>HeaP: Hierarchical Policies for Web Actions us...</td>\n",
       "      <td>Paloma Sodhi, S.R.K. Branavan, Ryan McDonald</td>\n",
       "      <td>https://arxiv.org/pdf/2310.03720.pdf</td>\n",
       "      <td>['Machine Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arXiv:2310.02794</td>\n",
       "      <td>Stability Improvements for Fast Matrix Multipl...</td>\n",
       "      <td>Charlotte Vermeylen, Marc Van Barel</td>\n",
       "      <td>https://arxiv.org/pdf/2310.02794.pdf</td>\n",
       "      <td>['Numerical Analysis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arXiv:2310.02656</td>\n",
       "      <td>Blend: A Unified Data Discovery System</td>\n",
       "      <td>Mahdi Esmailoghli, Christoph Schnell, Renée J....</td>\n",
       "      <td>https://arxiv.org/pdf/2310.02656.pdf</td>\n",
       "      <td>['Databases']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arXiv:2310.00977</td>\n",
       "      <td>Position Sensing Errors in Synchronous Motor D...</td>\n",
       "      <td>Prerit Pramod</td>\n",
       "      <td>https://arxiv.org/pdf/2310.00977.pdf</td>\n",
       "      <td>['Systems', 'Control']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arXiv:2310.00605</td>\n",
       "      <td>The Generalized Matrix Norm Problem</td>\n",
       "      <td>Adrian Kulmburg</td>\n",
       "      <td>https://arxiv.org/pdf/2310.00605.pdf</td>\n",
       "      <td>['Numerical Analysis']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arXiv:2310.00105</td>\n",
       "      <td>Latent Space Symmetry Discovery</td>\n",
       "      <td>Jianke Yang, Nima Dehmamy, Robin Walters, Rose Yu</td>\n",
       "      <td>https://arxiv.org/pdf/2310.00105.pdf</td>\n",
       "      <td>['Machine Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arXiv:2310.00073</td>\n",
       "      <td>Multi-Objective Sparse Sensing with Ergodic Op...</td>\n",
       "      <td>Ananya Rao, Howie Choset</td>\n",
       "      <td>https://arxiv.org/pdf/2310.00073.pdf</td>\n",
       "      <td>['Robotics', 'Optimization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arXiv:2310.00817</td>\n",
       "      <td>Learning to Make Adherence-Aware Advice</td>\n",
       "      <td>Guanting Chen, Xiaocheng Li, Chunlin Sun, Hanz...</td>\n",
       "      <td>https://arxiv.org/pdf/2310.00817.pdf</td>\n",
       "      <td>['Machine Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arXiv:2309.16809</td>\n",
       "      <td>GraB-sampler: Optimal Permutation-based SGD Da...</td>\n",
       "      <td>Guanghao Wei</td>\n",
       "      <td>https://arxiv.org/pdf/2309.16809.pdf</td>\n",
       "      <td>['Machine Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arXiv:2310.08450</td>\n",
       "      <td>Monotone discretizations of levelset convex ge...</td>\n",
       "      <td>Jeff Calder, Wonjun Lee</td>\n",
       "      <td>https://arxiv.org/pdf/2310.08450.pdf</td>\n",
       "      <td>['Numerical Analysis']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              title  \\\n",
       "0  arXiv:2310.03720  HeaP: Hierarchical Policies for Web Actions us...   \n",
       "1  arXiv:2310.02794  Stability Improvements for Fast Matrix Multipl...   \n",
       "2  arXiv:2310.02656             Blend: A Unified Data Discovery System   \n",
       "3  arXiv:2310.00977  Position Sensing Errors in Synchronous Motor D...   \n",
       "4  arXiv:2310.00605                The Generalized Matrix Norm Problem   \n",
       "5  arXiv:2310.00105                    Latent Space Symmetry Discovery   \n",
       "6  arXiv:2310.00073  Multi-Objective Sparse Sensing with Ergodic Op...   \n",
       "7  arXiv:2310.00817            Learning to Make Adherence-Aware Advice   \n",
       "8  arXiv:2309.16809  GraB-sampler: Optimal Permutation-based SGD Da...   \n",
       "9  arXiv:2310.08450  Monotone discretizations of levelset convex ge...   \n",
       "\n",
       "                                             authors  \\\n",
       "0       Paloma Sodhi, S.R.K. Branavan, Ryan McDonald   \n",
       "1                Charlotte Vermeylen, Marc Van Barel   \n",
       "2  Mahdi Esmailoghli, Christoph Schnell, Renée J....   \n",
       "3                                      Prerit Pramod   \n",
       "4                                    Adrian Kulmburg   \n",
       "5  Jianke Yang, Nima Dehmamy, Robin Walters, Rose Yu   \n",
       "6                           Ananya Rao, Howie Choset   \n",
       "7  Guanting Chen, Xiaocheng Li, Chunlin Sun, Hanz...   \n",
       "8                                       Guanghao Wei   \n",
       "9                            Jeff Calder, Wonjun Lee   \n",
       "\n",
       "                                    url                 subject_split  \n",
       "0  https://arxiv.org/pdf/2310.03720.pdf          ['Machine Learning']  \n",
       "1  https://arxiv.org/pdf/2310.02794.pdf        ['Numerical Analysis']  \n",
       "2  https://arxiv.org/pdf/2310.02656.pdf                 ['Databases']  \n",
       "3  https://arxiv.org/pdf/2310.00977.pdf        ['Systems', 'Control']  \n",
       "4  https://arxiv.org/pdf/2310.00605.pdf        ['Numerical Analysis']  \n",
       "5  https://arxiv.org/pdf/2310.00105.pdf          ['Machine Learning']  \n",
       "6  https://arxiv.org/pdf/2310.00073.pdf  ['Robotics', 'Optimization']  \n",
       "7  https://arxiv.org/pdf/2310.00817.pdf          ['Machine Learning']  \n",
       "8  https://arxiv.org/pdf/2309.16809.pdf          ['Machine Learning']  \n",
       "9  https://arxiv.org/pdf/2310.08450.pdf        ['Numerical Analysis']  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connection details\n",
    "db_user = 'postgres'\n",
    "db_password = 'admin'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'AOI'\n",
    "\n",
    "# format special characters\n",
    "password = quote_plus(db_password)\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    host=db_host,\n",
    "    port=db_port\n",
    ")\n",
    "\n",
    "# SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{db_user}:{password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# PostgreSQL tables -> pandas DataFrames\n",
    "researchers_query = 'SELECT \"Researcher ID\", \"Full Name\", \"Expertise\", \"Appreciated\", \"Random Recommendation\" FROM researchers_table'\n",
    "articles_query = 'SELECT id, title, authors, url, subject_split FROM articles_table'\n",
    "\n",
    "researchers_df = pd.read_sql(researchers_query, engine)\n",
    "articles_df = pd.read_sql(articles_query, engine)\n",
    "\n",
    "# researchers_df.head(33)\n",
    "articles_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_matches(target_researcher_id, researchers_df):\n",
    "\n",
    "    max_common_count = 0\n",
    "    most_common_person = 'Not Found'\n",
    "\n",
    "    target_appreciated_articles = researchers_df.loc[researchers_df['Researcher ID'] == target_researcher_id, 'Appreciated'].values[0].split(', ')\n",
    "    # target_appreciated_articles.extend(researchers_df.loc[researchers_df['Researcher ID'] == target_researcher_id, 'Random Recommendation'].values[0].split(', '))\n",
    "\n",
    "    for _, researcher in researchers_df.iterrows():\n",
    "        if researcher['Researcher ID'] != target_researcher_id:\n",
    "\n",
    "            other_appreciated_articles = researcher['Appreciated'].split(', ')\n",
    "            # other_appreciated_articles.extend(researcher['Random Recommendation'].split(', '))\n",
    "            # print(\"target \", target_appreciated_articles)\n",
    "            # print(\"other \", other_appreciated_articles)\n",
    "\n",
    "            common_articles = set(other_appreciated_articles) & set(target_appreciated_articles)\n",
    "            common_count = len(common_articles)\n",
    "\n",
    "            if common_count > max_common_count and common_count < nr_of_recommendations:\n",
    "                max_common_count = common_count\n",
    "                most_common_person = researcher['Researcher ID']\n",
    "\n",
    "                \n",
    "    return most_common_person, max_common_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For researcher ROSNER, Daniel, the best match is MOISESCU, Mihnea Alexandru with a match of 9 common articles\n",
      "For researcher RUSETI, Stefan, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher TAPUS, Nicolae, the best match is NEGRU, Catalin with a match of 40 common articles\n",
      "For researcher CIRTOAJE, Cristina, the best match is FLOREA, Adina Magda with a match of 1 common articles\n",
      "For researcher REBEDEA, Traian, the best match is CHIRU, Costin Gabriel with a match of 11 common articles\n",
      "For researcher MOCANU, Irina, the best match is CHIRU, Costin Gabriel with a match of 4 common articles\n",
      "For researcher DEACONESCU, Razvan, the best match is TIGANOAIA, Bogdan with a match of 1 common articles\n",
      "For researcher DASCALU, Mihai, the best match is CHIRU, Costin Gabriel with a match of 16 common articles\n",
      "For researcher MOCANU, Bogdan Costel, the best match is TAPUS, Nicolae with a match of 39 common articles\n",
      "For researcher DOBRE, Ciprian Mihai, the best match is LEORDEANU, Catalin with a match of 30 common articles\n",
      "For researcher TRUICA, Ciprian Octavian, the best match is REBEDEA, Traian with a match of 1 common articles\n",
      "For researcher RUGHINIS, Razvan Victor, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "No match found for RADULESCU, Florin\n",
      "For researcher VADUVA, Alexandru Jan, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher POP, Florin, the best match is NEGRU, Catalin with a match of 27 common articles\n",
      "For researcher SLUSANSCHI, Emil Ioan, the best match is OLTEANU, Alexandru with a match of 13 common articles\n",
      "For researcher LEORDEANU, Catalin, the best match is APOSTOL, Elena Simona with a match of 34 common articles\n",
      "For researcher OLTEANU, Alexandru, the best match is APOSTOL, Elena Simona with a match of 25 common articles\n",
      "For researcher RADOI, Ion Emilian, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher STANILOIU, Constantin Eduard, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher TIGANOAIA, Bogdan, the best match is STOICAN, Florin with a match of 41 common articles\n",
      "For researcher CARABAS, Costin, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher CHIRU, Costin Gabriel, the best match is DASCALU, Mihai with a match of 16 common articles\n",
      "For researcher FLOREA, Adina Magda, the best match is TAPUS, Nicolae with a match of 1 common articles\n",
      "For researcher MOCANU, Mariana Ionela, the best match is RUSETI, Stefan with a match of 41 common articles\n",
      "For researcher MOISESCU, Mihnea Alexandru, the best match is RADOVICI, Alexandru with a match of 11 common articles\n",
      "For researcher NEGRU, Catalin, the best match is TAPUS, Nicolae with a match of 40 common articles\n",
      "For researcher RADOVICI, Alexandru, the best match is RUSETI, Stefan with a match of 35 common articles\n",
      "For researcher TUDOSE, Dan Stefan, the best match is MOCANU, Mariana Ionela with a match of 41 common articles\n",
      "For researcher APOSTOL, Elena Simona, the best match is LEORDEANU, Catalin with a match of 34 common articles\n",
      "For researcher STOICAN, Florin, the best match is TIGANOAIA, Bogdan with a match of 41 common articles\n"
     ]
    }
   ],
   "source": [
    "best_matches = defaultdict()\n",
    "nr_of_matches = defaultdict()\n",
    "\n",
    "for index, researcher in researchers_df.iterrows():\n",
    "\n",
    "    researcher_id = researcher['Researcher ID']\n",
    "    most_common_person, max_common_count = find_most_matches(target_researcher_id=researcher['Researcher ID'], researchers_df=researchers_df)\n",
    "\n",
    "    if max_common_count != 0:\n",
    "        found_person_name = researchers_df.loc[researchers_df['Researcher ID'] == most_common_person, 'Full Name'].values[0]\n",
    "        found_person_id = researchers_df.loc[researchers_df['Researcher ID'] == most_common_person, 'Researcher ID'].values[0]\n",
    "        print(f\"For researcher {researcher['Full Name']}, the best match is {found_person_name} with a match of {max_common_count} common articles\")\n",
    "        \n",
    "        best_matches[researcher_id] = found_person_id\n",
    "        nr_of_matches[researcher_id] = max_common_count\n",
    "\n",
    "    else:\n",
    "        print(f\"No match found for {researcher['Full Name']}\")\n",
    "        best_matches[researcher_id] = 'None'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best match to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    host=db_host,\n",
    "    port=db_port\n",
    ")\n",
    "# cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, researcher in researchers_df.iterrows():\n",
    "    researcher_id = researcher['Researcher ID']\n",
    "    match_id = best_matches[researcher_id]\n",
    "    # print(f\"For researcher with id {researcher_id} the best match is {match_id}\")\n",
    "    update_query = f\"UPDATE researchers_table SET \\\"Best Match ID\\\" = '{match_id}' WHERE \\\"Researcher ID\\\" = '{researcher_id}'\"\n",
    "    cursor.execute(update_query)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch new changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Researcher ID</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Expertise</th>\n",
       "      <th>Appreciated</th>\n",
       "      <th>Random Recommendation</th>\n",
       "      <th>Best Match ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAG-9392-2021</td>\n",
       "      <td>APOSTOL, Elena Simona</td>\n",
       "      <td>['Distributed systems', 'IT security', 'Parall...</td>\n",
       "      <td>[\"arXiv:2310.02113\", \"arXiv:2310.05269\", \"arXi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>D-7296-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JCE-1061-2023</td>\n",
       "      <td>CARABAS, Costin</td>\n",
       "      <td>['Computer Science', 'Software Engineering', '...</td>\n",
       "      <td>[\"arXiv:2310.00562\", \"arXiv:2310.03736\", \"arXi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>E-4073-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAY-5210-2020</td>\n",
       "      <td>CHIRU, Costin Gabriel</td>\n",
       "      <td>['NLP', 'Machine learning', 'Artificial intell...</td>\n",
       "      <td>[\"arXiv:2310.02357\", \"arXiv:2310.14261\", \"arXi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>O-4984-2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-5751-2009</td>\n",
       "      <td>CIRTOAJE, Cristina</td>\n",
       "      <td>['Liquid crystal', 'Liquid crystals, polarised...</td>\n",
       "      <td>[\"arXiv:2310.04022\", \"arXiv:2310.10524\", \"arXi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>G-5326-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O-4984-2014</td>\n",
       "      <td>DASCALU, Mihai</td>\n",
       "      <td>['NLP', 'Discourse analysis', 'Learning analyt...</td>\n",
       "      <td>[\"arXiv:2310.02357\", \"arXiv:2310.00603\", \"arXi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>AAY-5210-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Researcher ID              Full Name  \\\n",
       "0  AAG-9392-2021  APOSTOL, Elena Simona   \n",
       "1  JCE-1061-2023        CARABAS, Costin   \n",
       "2  AAY-5210-2020  CHIRU, Costin Gabriel   \n",
       "3    C-5751-2009     CIRTOAJE, Cristina   \n",
       "4    O-4984-2014         DASCALU, Mihai   \n",
       "\n",
       "                                           Expertise  \\\n",
       "0  ['Distributed systems', 'IT security', 'Parall...   \n",
       "1  ['Computer Science', 'Software Engineering', '...   \n",
       "2  ['NLP', 'Machine learning', 'Artificial intell...   \n",
       "3  ['Liquid crystal', 'Liquid crystals, polarised...   \n",
       "4  ['NLP', 'Discourse analysis', 'Learning analyt...   \n",
       "\n",
       "                                         Appreciated Random Recommendation  \\\n",
       "0  [\"arXiv:2310.02113\", \"arXiv:2310.05269\", \"arXi...                    []   \n",
       "1  [\"arXiv:2310.00562\", \"arXiv:2310.03736\", \"arXi...                    []   \n",
       "2  [\"arXiv:2310.02357\", \"arXiv:2310.14261\", \"arXi...                    []   \n",
       "3  [\"arXiv:2310.04022\", \"arXiv:2310.10524\", \"arXi...                    []   \n",
       "4  [\"arXiv:2310.02357\", \"arXiv:2310.00603\", \"arXi...                    []   \n",
       "\n",
       "   Best Match ID  \n",
       "0    D-7296-2012  \n",
       "1    E-4073-2016  \n",
       "2    O-4984-2014  \n",
       "3    G-5326-2016  \n",
       "4  AAY-5210-2020  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researchers_query = 'SELECT * FROM researchers_table ORDER BY \\\"Full Name\\\"'\n",
    "researchers_df = pd.read_sql(researchers_query, engine)\n",
    "researchers_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights(interests):\n",
    "\n",
    "    num_interests = len(interests)\n",
    "    weights = []\n",
    "    weight = 0.9\n",
    "\n",
    "    for i in range(num_interests):\n",
    "        weights.append((interests[i], round(weight, 3)))\n",
    "        weight *= 0.8\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance(article_subjects, researcher_interests):\n",
    "    \n",
    "    researcher_interests_dict = dict(researcher_interests)\n",
    "    matched_subjects = []    \n",
    "    relevance_score = 0\n",
    "    \n",
    "    for subject in article_subjects:\n",
    "        for interest, weight in researcher_interests_dict.items():\n",
    "            if (interest.lower() == subject.lower()) or (subject.lower() == \"security\" and interest.lower() == \"it security\"):\n",
    "                relevance_score += weight\n",
    "                matched_subjects.append(interest)\n",
    "    \n",
    "    return relevance_score, matched_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_recom_filepath = os.path.join(os.getcwd(), \"Hybrid_Recommendation_Results.md\")\n",
    "top_articles = defaultdict()\n",
    "\n",
    "with open(content_recom_filepath, 'w', encoding='utf-8') as file:\n",
    "\n",
    "    for index, researcher in researchers_df.iterrows():\n",
    "\n",
    "        current_id = researcher['Researcher ID']\n",
    "        current_name = researcher['Full Name']\n",
    "        current_expertise = eval(researcher['Expertise'])\n",
    "        current_appreciated = set(eval(researcher['Appreciated']))\n",
    "        \n",
    "        match_id = researcher['Best Match ID']\n",
    "        if match_id != 'None':\n",
    "            match_name = researchers_df.loc[researchers_df['Researcher ID'] == match_id, 'Full Name'].values[0]\n",
    "            match_expertise = eval(researchers_df.loc[researchers_df['Researcher ID'] == match_id, 'Expertise'].values[0])\n",
    "            match_appreciated = set(eval(researchers_df.loc[researchers_df['Researcher ID'] == match_id, 'Appreciated'].values[0]))\n",
    "\n",
    "            possible_recommendations = match_appreciated - current_appreciated\n",
    "            # print(len(possible_recommendations))\n",
    "            filtered_articles = articles_df[articles_df['id'].isin(possible_recommendations)]\n",
    "            # print(filtered_articles['title'])\n",
    "\n",
    "            num_interests = len(current_expertise)\n",
    "            weighted_interests = assign_weights(current_expertise)\n",
    "            articles_relevance = []\n",
    "\n",
    "\n",
    "            for index_a, article in filtered_articles.iterrows():\n",
    "                article_id = article['id']\n",
    "                article_subjects_as_string = article['subject_split']\n",
    "                article_subjects = ast.literal_eval(article_subjects_as_string)\n",
    "                # compute relevance score for current article\n",
    "                relevance_score, matched_subjects = compute_relevance(article_subjects, weighted_interests)\n",
    "                articles_relevance.append((article, relevance_score, matched_subjects))\n",
    "\n",
    "\n",
    "            # only keep articles with relevance_score > 0\n",
    "            non_zero_articles = [art for art in articles_relevance if art[1] > 0]\n",
    "            # sort articles based on relevance score\n",
    "            non_zero_articles.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            top_articles[current_id] = non_zero_articles\n",
    "\n",
    "            \n",
    "            file.write(\"\\n\")\n",
    "            file.write(f\"# Researcher {current_name}\\n\")\n",
    "            file.write(f\"### **Expertise List:** {' | '.join(current_expertise)}\\n\\n\")\n",
    "            file.write(f\"## **Best match: Researcher {match_name}** with **{nr_of_matches[current_id]} matched appreciated articles**\\n\")\n",
    "            file.write(f\"### Their expertise list: {' | '.join(match_expertise)}\\n\")\n",
    "            file.write(f\"## **Hybrid Recommendations** for **{current_name}**\\n\")\n",
    "            file.write(\"| Nr | ID | URL | Title | Relevance Score | Matched Subjects | Article Subjects |\\n\")\n",
    "            file.write(\"| --- | --- | --- | --- | --- | --- | --- | \\n\")\n",
    "            index = 1\n",
    "            for article, relevance_score, matched_subjects in top_articles[current_id]:\n",
    "                file.write(f\"| {index} | {article['id']} | {article['url']} | {article['title']} | {relevance_score} | {matched_subjects} | {article['subject_split']} |\\n\")\n",
    "                index += 1\n",
    "            file.write(\"\\n\\n\\n\")\n",
    "                \n",
    "        \n",
    "\n",
    "    # print(f\"Researcher {current_name} with id {current_id} has an expertise in {current_expertise} and is best matched with {match_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
